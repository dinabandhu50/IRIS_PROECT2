{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/iris.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     0    1    2    3            4\n0  5.1  3.5  1.4  0.2  Iris-setosa\n1  4.9  3.0  1.4  0.2  Iris-setosa\n2  4.7  3.2  1.3  0.2  Iris-setosa\n3  4.6  3.1  1.5  0.2  Iris-setosa\n4  5.0  3.6  1.4  0.2  Iris-setosa\n5  5.4  3.9  1.7  0.4  Iris-setosa\n6  4.6  3.4  1.4  0.3  Iris-setosa\n7  5.0  3.4  1.5  0.2  Iris-setosa\n8  4.4  2.9  1.4  0.2  Iris-setosa\n9  4.9  3.1  1.5  0.1  Iris-setosa",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['x1','x2','x3','x4','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y',axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "z = le.inverse_transform([0,1,2])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      x1   x2   x3   x4\n39   5.1  3.4  1.5  0.2\n36   5.5  3.5  1.3  0.2\n117  7.7  3.8  6.7  2.2\n139  6.9  3.1  5.4  2.1\n107  7.3  2.9  6.3  1.8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>5.1</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>5.5</td>\n      <td>3.5</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>7.7</td>\n      <td>3.8</td>\n      <td>6.7</td>\n      <td>2.2</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>6.9</td>\n      <td>3.1</td>\n      <td>5.4</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>7.3</td>\n      <td>2.9</td>\n      <td>6.3</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "x1    0\nx2    0\nx3    0\nx4    0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "\n",
    "pca = PCA()\n",
    "standard = StandardScaler()\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('pca',pca),\n",
    "    ('standard_scailer',standard)\n",
    "    ])\n",
    "\n",
    "# output_transformer = Pipeline([\n",
    "#     ('le',le)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column separations\n",
    "numeric_cols = df.columns[:-1]\n",
    "# output_cols = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num',numeric_transformer,numeric_cols),\n",
    "    # ('output',output_transformer,output_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "rfc = Pipeline([\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('clf',clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('pca',\n                                                                   PCA()),\n                                                                  ('standard_scailer',\n                                                                   StandardScaler())]),\n                                                  Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))])),\n                ('clf', RandomForestClassifier())])"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n       2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2,\n       1, 2, 0, 0, 0, 1])"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "pred = rfc.predict(X_test)\n",
    "pred\n",
    "# le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa',\n       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n       'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',\n       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',\n       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor',\n       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',\n       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n       'Iris-virginica', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n       'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',\n       'Iris-setosa', 'Iris-versicolor', 'Iris-virginica',\n       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n       'Iris-setosa', 'Iris-versicolor'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.95      0.95      0.95        19\n           2       0.93      0.93      0.93        14\n\n    accuracy                           0.96        50\n   macro avg       0.96      0.96      0.96        50\nweighted avg       0.96      0.96      0.96        50\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.96"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LinearSVC(),\n",
    "    NuSVC(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LinearSVC()\naccuracy score:  0.9000\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.94      0.79      0.86        19\n           2       0.76      0.93      0.84        14\n\n    accuracy                           0.90        50\n   macro avg       0.90      0.91      0.90        50\nweighted avg       0.91      0.90      0.90        50\n\n\n\nNuSVC()\naccuracy score:  0.9200\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.89      0.89      0.89        19\n           2       0.86      0.86      0.86        14\n\n    accuracy                           0.92        50\n   macro avg       0.92      0.92      0.92        50\nweighted avg       0.92      0.92      0.92        50\n\n\n\nSVC()\naccuracy score:  0.9200\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.89      0.89      0.89        19\n           2       0.86      0.86      0.86        14\n\n    accuracy                           0.92        50\n   macro avg       0.92      0.92      0.92        50\nweighted avg       0.92      0.92      0.92        50\n\n\n\nDecisionTreeClassifier()\naccuracy score:  0.8800\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.88      0.79      0.83        19\n           2       0.75      0.86      0.80        14\n\n    accuracy                           0.88        50\n   macro avg       0.88      0.88      0.88        50\nweighted avg       0.89      0.88      0.88        50\n\n\n\nRandomForestClassifier()\naccuracy score:  0.9800\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.95      1.00      0.97        19\n           2       1.00      0.93      0.96        14\n\n    accuracy                           0.98        50\n   macro avg       0.98      0.98      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n\n\nAdaBoostClassifier()\naccuracy score:  0.9600\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.95      0.95      0.95        19\n           2       0.93      0.93      0.93        14\n\n    accuracy                           0.96        50\n   macro avg       0.96      0.96      0.96        50\nweighted avg       0.96      0.96      0.96        50\n\n\n\nGradientBoostingClassifier()\naccuracy score:  0.9600\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.95      0.95      0.95        19\n           2       0.93      0.93      0.93        14\n\n    accuracy                           0.96        50\n   macro avg       0.96      0.96      0.96        50\nweighted avg       0.96      0.96      0.96        50\n\n\n\nLogisticRegression()\naccuracy score:  0.9000\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       0.94      0.79      0.86        19\n           2       0.76      0.93      0.84        14\n\n    accuracy                           0.90        50\n   macro avg       0.90      0.91      0.90        50\nweighted avg       0.91      0.90      0.90        50\n\n\n\nLinearDiscriminantAnalysis()\naccuracy score:  1.0000\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       1.00      1.00      1.00        19\n           2       1.00      1.00      1.00        14\n\n    accuracy                           1.00        50\n   macro avg       1.00      1.00      1.00        50\nweighted avg       1.00      1.00      1.00        50\n\n\n\nQuadraticDiscriminantAnalysis()\naccuracy score:  1.0000\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       1.00      1.00      1.00        19\n           2       1.00      1.00      1.00        14\n\n    accuracy                           1.00        50\n   macro avg       1.00      1.00      1.00        50\nweighted avg       1.00      1.00      1.00        50\n\n\n\n"
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    pipe = Pipeline([\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('clf',clf)])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    print(clf)\n",
    "    print(f'accuracy score: {accuracy_score(y_test,pred): .4f}')\n",
    "    print(classification_report(y_test,pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best Linear Discrimination Analysis is looking like the best predicting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search CV for best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('clf',LinearDiscriminantAnalysis())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'preprocessor__num__pca__n_components':[1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe,param_grid=param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('preprocessor',\n   ColumnTransformer(transformers=[('num',\n                                    Pipeline(steps=[('pca', PCA()),\n                                                    ('standard_scailer',\n                                                     StandardScaler())]),\n                                    Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))])),\n  ('clf', LinearDiscriminantAnalysis())],\n 'verbose': False,\n 'preprocessor': ColumnTransformer(transformers=[('num',\n                                  Pipeline(steps=[('pca', PCA()),\n                                                  ('standard_scailer',\n                                                   StandardScaler())]),\n                                  Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))]),\n 'clf': LinearDiscriminantAnalysis(),\n 'preprocessor__n_jobs': None,\n 'preprocessor__remainder': 'drop',\n 'preprocessor__sparse_threshold': 0.3,\n 'preprocessor__transformer_weights': None,\n 'preprocessor__transformers': [('num',\n   Pipeline(steps=[('pca', PCA()), ('standard_scailer', StandardScaler())]),\n   Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))],\n 'preprocessor__verbose': False,\n 'preprocessor__num': Pipeline(steps=[('pca', PCA()), ('standard_scailer', StandardScaler())]),\n 'preprocessor__num__memory': None,\n 'preprocessor__num__steps': [('pca', PCA()),\n  ('standard_scailer', StandardScaler())],\n 'preprocessor__num__verbose': False,\n 'preprocessor__num__pca': PCA(),\n 'preprocessor__num__standard_scailer': StandardScaler(),\n 'preprocessor__num__pca__copy': True,\n 'preprocessor__num__pca__iterated_power': 'auto',\n 'preprocessor__num__pca__n_components': None,\n 'preprocessor__num__pca__random_state': None,\n 'preprocessor__num__pca__svd_solver': 'auto',\n 'preprocessor__num__pca__tol': 0.0,\n 'preprocessor__num__pca__whiten': False,\n 'preprocessor__num__standard_scailer__copy': True,\n 'preprocessor__num__standard_scailer__with_mean': True,\n 'preprocessor__num__standard_scailer__with_std': True,\n 'clf__n_components': None,\n 'clf__priors': None,\n 'clf__shrinkage': None,\n 'clf__solver': 'svd',\n 'clf__store_covariance': False,\n 'clf__tol': 0.0001}"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('pca',\n                                                                                          PCA()),\n                                                                                         ('standard_scailer',\n                                                                                          StandardScaler())]),\n                                                                         Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))])),\n                                       ('clf', LinearDiscriminantAnalysis())]),\n             param_grid={'preprocessor__num__pca__n_components': [1, 2, 3]})"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('preprocessor',\n   ColumnTransformer(transformers=[('num',\n                                    Pipeline(steps=[('pca', PCA(n_components=3)),\n                                                    ('standard_scailer',\n                                                     StandardScaler())]),\n                                    Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))])),\n  ('clf', LinearDiscriminantAnalysis())],\n 'verbose': False,\n 'preprocessor': ColumnTransformer(transformers=[('num',\n                                  Pipeline(steps=[('pca', PCA(n_components=3)),\n                                                  ('standard_scailer',\n                                                   StandardScaler())]),\n                                  Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))]),\n 'clf': LinearDiscriminantAnalysis(),\n 'preprocessor__n_jobs': None,\n 'preprocessor__remainder': 'drop',\n 'preprocessor__sparse_threshold': 0.3,\n 'preprocessor__transformer_weights': None,\n 'preprocessor__transformers': [('num',\n   Pipeline(steps=[('pca', PCA(n_components=3)),\n                   ('standard_scailer', StandardScaler())]),\n   Index(['x1', 'x2', 'x3', 'x4'], dtype='object'))],\n 'preprocessor__verbose': False,\n 'preprocessor__num': Pipeline(steps=[('pca', PCA(n_components=3)),\n                 ('standard_scailer', StandardScaler())]),\n 'preprocessor__num__memory': None,\n 'preprocessor__num__steps': [('pca', PCA(n_components=3)),\n  ('standard_scailer', StandardScaler())],\n 'preprocessor__num__verbose': False,\n 'preprocessor__num__pca': PCA(n_components=3),\n 'preprocessor__num__standard_scailer': StandardScaler(),\n 'preprocessor__num__pca__copy': True,\n 'preprocessor__num__pca__iterated_power': 'auto',\n 'preprocessor__num__pca__n_components': 3,\n 'preprocessor__num__pca__random_state': None,\n 'preprocessor__num__pca__svd_solver': 'auto',\n 'preprocessor__num__pca__tol': 0.0,\n 'preprocessor__num__pca__whiten': False,\n 'preprocessor__num__standard_scailer__copy': True,\n 'preprocessor__num__standard_scailer__with_mean': True,\n 'preprocessor__num__standard_scailer__with_std': True,\n 'clf__n_components': None,\n 'clf__priors': None,\n 'clf__shrinkage': None,\n 'clf__solver': 'svd',\n 'clf__store_covariance': False,\n 'clf__tol': 0.0001}"
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'preprocessor__num__pca__n_components': 3}"
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitirisconda577a6f56c9714782917559126937ed0d",
   "display_name": "Python 3.7.7 64-bit ('iris': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}